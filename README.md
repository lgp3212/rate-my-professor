# rate-my-professor
ğŸ“Š EDA digging into biases in RMP data

## ğŸ”§ Data Processing
- **Weighted Rating**: `avg_rating Ã— log(num_ratings)` to handle rating volume bias
- **STEM Classification**: Binary encoding using keyword matching  
- **PCA**: Dimensionality reduction for regression models
- **Reproducibility**: Random seed `16987856`

## ğŸ“ˆ Key Findings

### ğŸ‘¨â€ğŸ« Gender Bias
- Male professors receive significantly higher ratings (p â‰ˆ 0)
- Cohen's d = 0.088 (small effect)

### ğŸ“ Experience vs Quality  
- High experience professors rated higher (p â‰ˆ 0)
- Cohen's d = 0.074 (small effect)

### ğŸ“š Rating vs Difficulty
- Strong negative correlation: r = -0.537
- 28.8% of rating variance explained by difficulty

### ğŸ’» Online vs In-Person
- In-person classes rated higher (p â‰ˆ 0)
- Cohen's d = 0.387 (small-moderate effect)

### ğŸ”„ Rating vs Retake Rate
- Strong positive correlation: r = 0.767
- 58.8% of rating variance explained

### ğŸŒ¶ï¸ "Hot or Not" Effect
- "Hot" professors rated significantly higher (p â‰ˆ 0)
- Cohen's d = 1.016 (large effect)

## ğŸ¤– Predictive Models

### Linear Regression (Rating from Difficulty)
- RÂ² = 0.29, RMSE = 0.95
- Coefficient: -0.61 (each difficulty point drops rating ~0.6)

### Multiple Regression (All Factors)
- RÂ² = 0.75, RMSE = 0.43
- 75% variance explained vs 29% difficulty-only

### Logistic Regression (Predicting "Hotness")
- Rating only: AUROC = 0.692
- All factors: AUROC = 0.742

## ğŸ¯ Extra Credit: STEM vs Humanities
- **No significant difference** in ratings (p = 0.096)
- STEM courses significantly more difficult (p â‰ˆ 0)
- Difficulty doesn't translate to rating bias

## ğŸ› ï¸ Tech Stack
- pandas, numpy, scipy, sklearn
- Mann-Whitney U tests, Pearson correlation
- PCA, Linear/Logistic regression
- Bootstrap validation
